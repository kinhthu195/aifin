{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://certificate.tpq.io/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI in Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workshop at Texas State University (October 2023)**\n",
    "\n",
    "**_Natural Language Processing_**\n",
    "\n",
    "Dr. Yves J. Hilpisch | The Python Quants GmbH | http://tpq.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'This is a short text. The text is used to illustrate NLP techniques with Python and the nltk package.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.count('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.replace('a', '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nltk` Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nltk.word_tokenize(text)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [w.lower() for w in t if len(w) > 3]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sorted(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = list(set(t))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.pos_tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I was running through the green fields. Later I was sitting on the green grass.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer(PorterStemmer.MARTIN_EXTENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[stemmer.stem(w) for w in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lemmatizer.lemmatize(w) for w in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.stop_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [w.lower() for w in nltk.word_tokenize(text)\n",
    "         if w.lower() not in nlp.stop_words\n",
    "             and len(w) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [stemmer.stem(w) for w in t]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [lemmatizer.lemmatize(w) for w in t]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple short text snippets\n",
    "texts = [\n",
    "    'I love Apple MacBooks.',\n",
    "    'Grappling is a wonderful sport.',\n",
    "    'Walking the dogs in nature nurtures your soul.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LDA topic model with 10 topics\n",
    "lda = LatentDirichletAllocation(n_components=3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the LDA model on the text data\n",
    "l = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the topics and their corresponding words\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-5:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install -y gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec([tokens], min_count=1, vector_size=100, window=5, sg=1)\n",
    "model.train([tokens], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv['green'].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv['sitting'].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generating word embeddings with Word2Vec, the output is a set of word vectors that represent the meaning of each word in the text. The output is typically a matrix or ndarray object that contains the word vectors, where each row corresponds to a word and each column corresponds to a dimension of the vector space. The number of dimensions is a hyperparameter that can be set when creating the Word2Vec model, and typically ranges from 50 to 300.\n",
    "\n",
    "The output of Word2Vec can be interpreted in various ways, depending on the specific application and context. Some common ways to interpret the output include:\n",
    "\n",
    "- Similarity: The cosine similarity between two word vectors can be used to measure the semantic similarity between the corresponding words. Words that are semantically similar will have similar word vectors and high cosine similarity values.\n",
    "- Clustering: The word vectors can be clustered using unsupervised learning algorithms such as k-means or hierarchical clustering to group similar words together. This can be useful for tasks such as topic modeling or text classification.\n",
    "- Visualization: The word vectors can be visualized in a lower-dimensional space using techniques such as principal component analysis (PCA) or t-SNE. This can help to identify patterns or relationships between words that are not apparent in the high-dimensional vector space.\n",
    "\n",
    "It is important to note that the output of Word2Vec is not always interpretable or meaningful, and may require further processing or analysis to be useful for downstream tasks. Additionally, the choice of hyperparameters such as the number of dimensions or the size of the training corpus can affect the quality and interpretability of the word embeddings.\n",
    "\n",
    "In general, the output of Word2Vec should be treated as a set of numerical representations of words that capture their meaning in a high-dimensional vector space. These representations can be used as input to various machine learning models or algorithms to perform tasks such as text classification, sentiment analysis, or information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Embedding Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Skip Gram\n",
    "\n",
    "**Explanation:** \n",
    "Skip Gram is one of the architectures of the Word2Vec model. It works by using a current word to predict the context words (words surrounding the current word). Given a specific word, the Skip Gram model tries to maximize the probability of predicting surrounding words in a certain window size.\n",
    "\n",
    "**Use Cases:** \n",
    "- Word similarity and analogy tasks.\n",
    "- Feeding word vectors into downstream NLP tasks such as sentiment analysis, named entity recognition, etc.\n",
    "- Visualizing word relationships.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's use the `gensim` library again to illustrate this with a simple example.\n",
    "\n",
    "```python\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Data\n",
    "sentences = [['dog', 'barks'], ['cat', 'meows'], ['bird', 'sings']]\n",
    "\n",
    "# Training a Skip Gram model\n",
    "model = Word2Vec(sentences, vector_size=100, window=2, min_count=1, sg=1, workers=4)\n",
    "model.train(sentences, total_examples=len(sentences), epochs=1000)\n",
    "\n",
    "# Finding similar words to 'dog'\n",
    "similar_words = model.wv.most_similar('dog')\n",
    "print(similar_words)\n",
    "```\n",
    "\n",
    "### 2. Common Bag Of Words (CBOW)\n",
    "\n",
    "**Explanation:** \n",
    "CBOW is the other architecture of the Word2Vec model. Instead of predicting the context from a word (as in Skip Gram), CBOW predicts a word from its context. Given a set of context words, CBOW tries to predict the word that is most likely to appear with those context words.\n",
    "\n",
    "**Use Cases:** \n",
    "- Like Skip Gram, CBOW's embeddings can be used for word similarity tasks, visualizations, and as features in downstream NLP tasks.\n",
    "- It's generally faster and requires less memory than Skip Gram.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Data\n",
    "sentences = [['dog', 'barks'], ['cat', 'meows'], ['bird', 'sings']]\n",
    "\n",
    "# Training a CBOW model\n",
    "model = Word2Vec(sentences, vector_size=100, window=2, min_count=1, sg=0, workers=4)\n",
    "model.train(sentences, total_examples=len(sentences), epochs=1000)\n",
    "\n",
    "# Finding similar words to 'dog'\n",
    "similar_words = model.wv.most_similar('dog')\n",
    "print(similar_words)\n",
    "```\n",
    "\n",
    "In both examples, we've used a very small dataset just for illustrative purposes. The `sg` parameter in the `Word2Vec` function determines the architecture: `sg=1` indicates Skip Gram and `sg=0` indicates CBOW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags have the following meaning:\n",
    "\n",
    "- CC: coordinating conjunction\n",
    "- CD: cardinal digit\n",
    "- DT: determiner\n",
    "- EX: existential there\n",
    "- FW: foreign word\n",
    "- IN: preposition or subordinating conjunction\n",
    "- JJ: adjective\n",
    "- JJR: adjective, comparative\n",
    "- JJS: adjective, superlative\n",
    "- LS: list marker\n",
    "- MD: modal\n",
    "- NN: noun, singular or mass\n",
    "- NNS: noun, plural\n",
    "- NNP: proper noun, singular\n",
    "- NNPS: proper noun, plural\n",
    "- PDT: predeterminer\n",
    "- POS: possessive ending\n",
    "- PRP: personal pronoun\n",
    "- PRP\\$: possessive pronoun\n",
    "- RB: adverb\n",
    "- RBR: adverb, comparative\n",
    "- RBS: adverb, superlative\n",
    "- RP: particle\n",
    "- SYM: symbol\n",
    "- TO: to\n",
    "- UH: interjection\n",
    "- VB: verb, base form\n",
    "- VBD: verb, past tense\n",
    "- VBG: verb, gerund or present participle\n",
    "- VBN: verb, past participle\n",
    "- VBP: verb, non-3rd person singular present\n",
    "- VBZ: verb, 3rd person singular present\n",
    "- WDT: wh-determiner\n",
    "- WP: wh-pronoun\n",
    "- WP$: possessive wh-pronoun\n",
    "- WRB: wh-adverb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://hilpisch.com/tpq_logo.png' width=\"35%\" align=\"right\">\n",
    "\n",
    "<br><br><a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">ai@tpq.io</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
