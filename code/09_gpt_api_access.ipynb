{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://certificate.tpq.io/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI in Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workshop at Texas State University (October 2023)**\n",
    "\n",
    "**_GPT API Access_**\n",
    "\n",
    "Dr. Yves J. Hilpisch | The Python Quants GmbH | http://cpf.tpq.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../creds.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETIONS_MODEL = \"text-davinci-002\"\n",
    "# COMPLETIONS_MODEL = \"gpt-3.5-turbo\"\n",
    "COMPLETIONS_MODEL = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(prompt):\n",
    "    answer = openai.ChatCompletion.create(\n",
    "        temperature=0,\n",
    "        max_tokens=500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "        model=COMPLETIONS_MODEL\n",
    "    )[\"choices\"][0]\n",
    "    print(answer['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Summarize the life of Dr. Yves Hilpisch. Only include details that you are sure about.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Yves Hilpisch is a renowned figure in the field of finance and technology, particularly known for his expertise in Python programming and its application in finance. He was born and raised in Germany.\n",
      "\n",
      "Dr. Hilpisch completed his undergraduate studies in Management and his doctoral degree in Mathematical Finance. He is the founder and managing partner of The Python Quants Group, a group dedicated to the use of open-source technologies for financial data science, algorithmic trading, and computational finance. He also founded the Fintech company, The AI Machine.\n",
      "\n",
      "He has written several books on the subject of Python in finance, including \"Python for Finance\", \"Derivatives Analytics with Python\" and \"Listed Volatility and Variance Derivatives\". His work is widely recognized and he is often invited to speak at conferences and seminars around the world.\n",
      "\n",
      "Dr. Hilpisch also contributes to the Python and finance community through his work as a lecturer and trainer. He has conducted numerous training sessions and workshops on Python for financial data analysis and algorithmic trading.\n",
      "\n",
      "Despite his busy schedule, Dr. Hilpisch is also involved in academia. He has taught at various universities and currently serves as an honorary professor at the University of Ulm in Germany.\n",
      "\n",
      "In summary, Dr. Yves Hilpisch is a leading figure in the intersection of finance and technology, with significant contributions to the field through his entrepreneurial ventures, academic work, and publications.\n"
     ]
    }
   ],
   "source": [
    "ask_question(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Can you summarize the life of Sandra Newedel-Hilpisch?\n",
    "If you are not sure, please answer with 'I do not know.'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have any information about Sandra Newedel-Hilpisch.\n"
     ]
    }
   ],
   "source": [
    "answer = ask_question(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least-Squares Monte Carlo (LSMC) is a method used in option pricing to estimate the expected payoff of an option. This method is particularly useful for pricing American options, which can be exercised at any time before expiration, making them more complex to price than European options, which can only be exercised at expiration.\n",
      "\n",
      "The LSMC method involves simulating a large number of possible price paths for the underlying asset and then calculating the payoff of the option for each path. The least squares part of the method comes into play when we try to estimate the continuation value of the option, which is the expected payoff from holding the option for a further period of time. This is done by fitting a regression model to the simulated payoffs, using the least squares method to minimize the difference between the actual and estimated payoffs.\n",
      "\n",
      "The LSMC method is a powerful tool for option pricing as it can handle a wide range of complex features, such as early exercise, path-dependency, and multiple underlying assets. However, it can be computationally intensive due to the large number of simulations required.\n"
     ]
    }
   ],
   "source": [
    "ask_question('What does Least-Squares Monte Carlo do in option pricing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Q-learning is a type of reinforcement learning algorithm that uses a neural network to approximate the Q-value function. The Q-value function is used to estimate the expected reward for each action in each state, which helps the agent to make the best decision.\n",
      "\n",
      "TicTacToe, on the other hand, is a simple game with a small state space, meaning there are not many possible game states to consider. This makes it relatively easy to learn using traditional reinforcement learning methods, such as Q-learning with a table.\n",
      "\n",
      "However, when using deep Q-learning to learn TicTacToe, several challenges may arise:\n",
      "\n",
      "1. Overfitting: Deep Q-learning uses a neural network to approximate the Q-value function. If the network is too complex, it may overfit to the training data, meaning it learns the training data too well and performs poorly on new, unseen data.\n",
      "\n",
      "2. Training instability: Deep Q-learning can be unstable and difficult to train. This is because the same network is used to generate both the current Q-values and the target Q-values for the next state. This can lead to a feedback loop where the network's predictions influence the training targets, leading to instability.\n",
      "\n",
      "3. Lack of exploration: Deep Q-learning uses an epsilon-greedy strategy for exploration, where the agent chooses a random action with probability epsilon and the best action according to the current Q-value function with probability 1-epsilon. If epsilon is too small, the agent may not explore the state space sufficiently, leading to suboptimal learning.\n",
      "\n",
      "4. Overestimation of Q-values: Deep Q-learning tends to overestimate Q-values due to its max operation in the update rule. This can lead to overly optimistic value estimates and suboptimal policies.\n",
      "\n",
      "5. Insufficient training data: TicTacToe is a simple game with a small state space. This means there may not be enough data to effectively train a deep Q-learning model, which typically requires a large amount of data.\n",
      "\n",
      "6. Discrete action space: TicTacToe has a discrete action space, meaning there are a finite number of actions the agent can take. This can make it difficult for the deep Q-learning model to generalize across different actions.\n",
      "\n",
      "In conclusion, while deep Q-learning can be a powerful tool for learning complex tasks with large state spaces, it may not be the best choice for simpler tasks like TicTacToe. Traditional reinforcement learning methods, such as Q-learning with a table, may be more effective in this case.\n"
     ]
    }
   ],
   "source": [
    "ask_question(\n",
    "'''\n",
    "Why is it so hard to learn TicTacToe with deep Q-learning?\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://hilpisch.com/tpq_logo.png' width=\"35%\" align=\"right\">\n",
    "\n",
    "<br><br><a href=\"http://cpf.tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
